{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03bcb91",
   "metadata": {},
   "source": [
    "[Jump to weekly activity](#Weekly-activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a091e",
   "metadata": {},
   "source": [
    "# Learning outcomes\n",
    "1. Overview of CV\n",
    "2. Revisit some important concepts of images as Numpy array.\n",
    "3. Cropping. Why? One of the data augmentation techniques in deep learning model development.\n",
    "4. Splitting and merging of color channels\n",
    "5. Mathematical operations\n",
    "6. Image blending (add 2 images together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6be24",
   "metadata": {},
   "source": [
    "## Setup (import modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fed691",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a8901",
   "metadata": {},
   "source": [
    "## Images as Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((2, 4), dtype=np.uint8)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bfcc8",
   "metadata": {},
   "source": [
    "The above 'img' variable belongs to grayscale image. Another primary types of image is **color image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6fa402",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "print(img_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0, 1] = 50\n",
    "img[1, 2] = 100\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7866fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color1 = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "print(img_color1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fdb84",
   "metadata": {},
   "source": [
    "## Access elements in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "a = img[49, 199, 2]\n",
    "b = img.item(49, 199, 2)\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a = img[49, 199, 2]\n",
    "%timeit b = img.item(49, 199, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece184b",
   "metadata": {},
   "source": [
    "## Numpy array slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top left region of lena image\n",
    "show_img(\"lena\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]\n",
    "\n",
    "topleft = img[:h//2, :w//2]\n",
    "\n",
    "show_img(\"topleft\", topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract central region of the image\n",
    "yc, wc = h//2, w//2\n",
    "\n",
    "centre = img[yc-30:yc+30, wc-30: wc+30]\n",
    "\n",
    "show_img(\"centre\", centre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7263d74",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Create a 200 x 200 white image and display it.\n",
    "2. Leverage your image processing skills to create a simple wallpaper design as shown in the following image: ![wallpaper](image_embed/exercise_w4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5761983",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create white image\n",
    "white = np.zeros((200, 200)) + 255\n",
    "white = np.uint8(white)\n",
    "\n",
    "show_img(\"white\", white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53b60b",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a repeating pattern\n",
    "img_arr = np.zeros((30, 30), dtype=np.uint8)\n",
    "\n",
    "img_arr[:10, 10:20] = 255\n",
    "img_arr[10:20, :10] = 255\n",
    "img_arr[10:20, 20:] = 255\n",
    "img_arr[20:, 10:20] = 255\n",
    "\n",
    "img = np.tile(img_arr, (3,3))\n",
    "\n",
    "show_img(\"pattern\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract flower\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "\n",
    "show_img(\"flower\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(cv) if i.startswith('EVENT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c005b22",
   "metadata": {},
   "source": [
    "Extract the region of interest (flower) from the 'flower.jfif'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40217cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: callback function\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "img_copy = img.copy()\n",
    "\n",
    "def rect_region(event, x, y, flags, params):\n",
    "    \"\"\"This is mouseclick callback function\"\"\"\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        print((x, y))\n",
    "        cv.circle(img, (x, y), 1, (0, 0, 255), -1)\n",
    "        cv.imshow(\"img\", img)\n",
    "        \n",
    "cv.imshow(\"img\", img)\n",
    "cv.setMouseCallback(\"img\", rect_region)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = img_copy[39:122, 93:175]\n",
    "\n",
    "show_img(\"flower\", flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "bbox = cv.selectROI(\"img\", img)\n",
    "\n",
    "# (x, y, w, h)\n",
    "flower = img[int(bbox[1]):  int(bbox[1]+bbox[3]),\n",
    "            int(bbox[0]): int(bbox[0]+bbox[2])]\n",
    "\n",
    "show_img(\"flower\", flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 3: paint app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e411239",
   "metadata": {},
   "source": [
    "## Image cropping\n",
    "Why?\n",
    "- Remove unwanted objects\n",
    "- Rule of thirds. Separate images into $3 \\times 3$ grids, and we place our camera in a way such that the object of interest is on the grid line or its intersection, the picture would look more appealing\n",
    "- One of the data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "img_copy = img.copy()\n",
    "\n",
    "# parameter definition\n",
    "h, w = img.shape[:2]\n",
    "n_vertical_grids = 4\n",
    "n_horizontal_grids = 4\n",
    "\n",
    "# we need to get the number of pixels for column and row\n",
    "M = int(h / n_vertical_grids)\n",
    "N = int(w / n_horizontal_grids)\n",
    "\n",
    "tiles = []\n",
    "for y in range(0, h, M):\n",
    "    for x in range(0, w, N):\n",
    "        x1 = x + N\n",
    "        y1 = y + M\n",
    "        \n",
    "        if x1 > w and y1 > h:\n",
    "            x1 = w - 1\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:h, x:w]\n",
    "            tiles.append(tile)\n",
    "        elif y1 > w:\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:h, x:x1]\n",
    "            tiles.append(tile)\n",
    "        elif x1 > w:\n",
    "            x1 = w - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:y1, x:w]\n",
    "            tiles.append(tile)\n",
    "        else:\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            tile = img[y:y1, x:x1]\n",
    "            tiles.append(tile)\n",
    "            \n",
    "show_img(\"crop\", img_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fda9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(\"patch\", tiles[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329b23a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Divide the image into 4 equal regions. Swap their positions as shown below: ![dog_swap](image_embed/crop_swap.png)\n",
    "2. Cover the face of lena with white mask as shown as the following: ![lena_mask](image_embed/lena_mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8509007",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "img_copy = img.copy()\n",
    "\n",
    "# parameter definition\n",
    "h, w = img.shape[:2]\n",
    "n_vertical_grids = 2\n",
    "n_horizontal_grids = 2\n",
    "\n",
    "# we need to get the number of pixels for column and row\n",
    "M = int(h / n_vertical_grids)\n",
    "N = int(w / n_horizontal_grids)\n",
    "\n",
    "tiles = []\n",
    "for y in range(0, h, M):\n",
    "    for x in range(0, w, N):\n",
    "        x1 = x + N\n",
    "        y1 = y + M\n",
    "        \n",
    "        if x1 > w and y1 > h:\n",
    "            x1 = w - 1\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:h, x:w]\n",
    "            tiles.append(tile)\n",
    "        elif y1 > w:\n",
    "            y1 = h - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:h, x:x1]\n",
    "            tiles.append(tile)\n",
    "        elif x1 > w:\n",
    "            x1 = w - 1\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            \n",
    "            tile = img[y:y1, x:w]\n",
    "            tiles.append(tile)\n",
    "        else:\n",
    "            cv.rectangle(img_copy, (x, y), (x1, y1), (0, 255, 0), 1)\n",
    "            tile = img[y:y1, x:x1]\n",
    "            tiles.append(tile)\n",
    "        \n",
    "img_copy[:M, :N] = tiles[3]\n",
    "img_copy[:M, N:] = tiles[2]\n",
    "img_copy[M:, :N] = tiles[1]\n",
    "img_copy[M:, N:] = tiles[0]\n",
    "\n",
    "show_img(\"swapped regions\", img_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb354a08",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "if img is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "    \n",
    "h, w = img.shape[:2]\n",
    "cx, cy = h//2, w//2\n",
    "\n",
    "cv.rectangle(img, (cx-30, cy-30), (cx+50, cy+50), (255, 255, 255), -1)\n",
    "\n",
    "show_img(\"lena mask\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e5ec6",
   "metadata": {},
   "source": [
    "## Splitting and merging of color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "# split image into separate channels\n",
    "b, g, r = cv.split(img)\n",
    "\n",
    "# merge\n",
    "img_merge = cv.merge((b, g, r))\n",
    "\n",
    "# test if the two arrays are the same\n",
    "np.array_equal(img, img_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6b180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "fig.suptitle(\"Different color channels\")\n",
    "\n",
    "ax1.imshow(b, cmap=plt.cm.gray)\n",
    "ax1.set(title=\"blue channel\", xticks=[], yticks=[])\n",
    "\n",
    "ax2.imshow(g, cmap=plt.cm.gray)\n",
    "ax2.set(title=\"green channel\", xticks=[], yticks=[])\n",
    "\n",
    "ax3.imshow(r, cmap=plt.cm.gray)\n",
    "ax3.set(title=\"red channel\", xticks=[], yticks=[])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply color filter\n",
    "img = cv.imread(\"images/dog.jfif\")\n",
    "\n",
    "colors = (\"blue\", \"green\", \"red\")\n",
    "\n",
    "channels = cv.split(img)\n",
    "\n",
    "imgs = []\n",
    "for i, ch in enumerate(channels):\n",
    "    img_arr = np.zeros_like(img)\n",
    "    img_arr[:, :, i] = ch\n",
    "    imgs.append(img_arr)\n",
    "    \n",
    "for img, c in zip(imgs, colors):\n",
    "    cv.imshow(c, img)\n",
    "    \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b447411",
   "metadata": {},
   "source": [
    "## Point operators (mathematical operations)\n",
    "$$ f_{trans}(\\textbf{x}) = \\alpha f(\\textbf{x}) + \\beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda39172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_op(img, alpha, beta):\n",
    "    \"\"\"Point operators. Arguments:\n",
    "    1. Source image\n",
    "    2. multiplier\n",
    "    3. constant\n",
    "    \"\"\"\n",
    "    img = img.astype(float)\n",
    "    res = alpha * img + beta\n",
    "    res = np.clip(res, 0, 255)\n",
    "    return np.uint8(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2176b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance brightness and contrast\n",
    "img = cv.imread(\"images/bridge.jfif\")\n",
    "\n",
    "transform = point_op(img, 2, 30)\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "show_img(\"transform\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2 = point_op(img, 1, -80)\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "show_img(\"transform\", transform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621943d",
   "metadata": {},
   "source": [
    "## gamma correction\n",
    "$$ O = (\\frac{I}{255})^\\gamma \\times 255 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428752c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/2.2\n",
    "\n",
    "lookUpTable = np.empty((1, 256), dtype=np.uint8)\n",
    "for i in range(256):\n",
    "    lookUpTable[0, i] = np.clip(pow(i/255, gamma) * 255, 0, 255)\n",
    "    \n",
    "img = cv.imread(\"images/mountains_prop.jpg\")\n",
    "res = cv.LUT(img, lookUpTable)\n",
    "\n",
    "cv.namedWindow(\"original\", cv.WINDOW_NORMAL)\n",
    "cv.imshow(\"original\", img)\n",
    "show_img(\"gamma correction\", res, adjust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f969b1e",
   "metadata": {},
   "source": [
    "## Images blending (add 2 images together)\n",
    "get a sense of transparency\n",
    "$$ g(\\textbf{x}) = \\alpha f(\\textbf{x}) + (1 - \\alpha)h(\\textbf{x}) + \\beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625cb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/lena.jfif\")\n",
    "img2 = cv.imread(\"images/coins.jfif\")\n",
    "\n",
    "# resize img2\n",
    "alpha = 0.8\n",
    "h, w = img.shape[:2]\n",
    "img2 = cv.resize(img2, (w, h))\n",
    "\n",
    "# blending\n",
    "res = cv.addWeighted(img, alpha, img2, 1-alpha, 0)\n",
    "\n",
    "cv.imshow(\"img1\", img)\n",
    "cv.imshow(\"img2\", img2)\n",
    "show_img(\"blending\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c036e9e",
   "metadata": {},
   "source": [
    "## Weekly activity\n",
    "1. Create a random noise color and grayscale image. You can set your own width and height, but keep the total number of pixels of both images identical.\n",
    "2. Convert the code chunk found under section Divide an image into smaller patches using cropping into a function with the following signature:\n",
    "\n",
    "crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color)\n",
    "* img is the source image\n",
    "* num_horizontal_grid and num_vertical_grid are the number of patches along x and y axes.\n",
    "line_color is the color of the grid line.\n",
    "* The output of the function should be image with grids\n",
    "3. Display image sequences of smooth transition of two images with different values of α. Refer to code in section \"Image blending\". Use \"lena.jfif\" and \"coins.jfif\" as the base images.\n",
    "4. Suppose you are a digital content creator and wish to share photo online. However, you wish to protect these images from being stolen or altered by others. Leverage your image processing knowledge to apply watermark on image \"travel_hd.jpg\". The example of resulting watermarked image are as shown in the following: ![activity_image](images/)\n",
    "\n",
    "Image courtesy: [Unsplash](#).\n",
    "\n",
    "Notice the watermark added to the bottom left of the image. You are free to design your own watermark icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8597fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e236b",
   "metadata": {},
   "source": [
    "Activity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise = np.random.randint(0, 255, size=(100, 100), dtype=np.uint8)\n",
    "grayscale = np.zeros((100, 100), dtype=np.uint8) + 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31efa7",
   "metadata": {},
   "source": [
    "Activity 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d432d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_grid(img, num_horizontal_grid, num_vertical_grid, line_color):\n",
    "    \"\"\"\n",
    "    * img is the source image\n",
    "    * num_horizontal_grid and num_vertical_grid are the number of patches along x and y axes.\n",
    "    * line_color is the color of the grid line. (BGR)\n",
    "    * The output of the function should be image with grids\n",
    "    \"\"\"\n",
    "    # we need to get the number of pixels for column and row\n",
    "    M = int(h / num_vertical_grid)\n",
    "    N = int(w / num_horizontal_grid)\n",
    "\n",
    "    for y in range(0, h, M):\n",
    "        for x in range(0, w, N):\n",
    "            x1 = x + N\n",
    "            y1 = y + M\n",
    "\n",
    "            if x1 > w and y1 > h:\n",
    "                x1 = w - 1\n",
    "                y1 = h - 1\n",
    "                cv.rectangle(img, (x, y), (x1, y1), line_color, 1)\n",
    "            elif y1 > w:\n",
    "                y1 = h - 1\n",
    "                cv.rectangle(img, (x, y), (x1, y1), line_color, 1)\n",
    "            elif x1 > w:\n",
    "                x1 = w - 1\n",
    "                cv.rectangle(img, (x, y), (x1, y1), line_color, 1)\n",
    "            else:\n",
    "                cv.rectangle(img, (x, y), (x1, y1), line_color, 1)\n",
    "    return img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b70f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/dog.jfif\")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "n_vertical_grids = 4\n",
    "n_horizontal_grids = 4\n",
    "\n",
    "grid_img = crop_grid(img, n_horizontal_grids, n_vertical_grids, (0, 255, 0))\n",
    "show_img(\"grid img\", grid_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb9a6c",
   "metadata": {},
   "source": [
    "Activity 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lena = cv.imread(\"images/lena.jfif\")\n",
    "img_coins = cv.imread(\"images/coins.jfif\")\n",
    "\n",
    "if img_lena is None: \n",
    "    raise Exception(\"lena image not found\")\n",
    "if img_coins is None:\n",
    "    raise Exception(\"coin image not found\")\n",
    "\n",
    "h, w = img_lena.shape[:2]\n",
    "img_coins = cv.resize(img_coins, (w, h))\n",
    "\n",
    "# transition from coins to lena image\n",
    "for alpha in np.linspace(0, 1, 11):\n",
    "    res = cv.addWeighted(img_lena, alpha, img_coins, 1-alpha, 0)\n",
    "    cv.imshow(\"blending\", res)\n",
    "    cv.waitKey(100)\n",
    "    \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43867f4",
   "metadata": {},
   "source": [
    "Activity 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using putText to insert 'watermark' into image\n",
    "img = cv.imread(\"images/travel_hd.jpg\")\n",
    "\n",
    "if img is None: \n",
    "    raise Exception(\"Image not found\")\n",
    "\n",
    "img = cv.resize(img, None, fx=0.1, fy=0.1)\n",
    "\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "y, x = img.shape[:2]\n",
    "res = cv.putText(img, \"UCCC2513 watermark\", (0, y-50), font, 1, (255, 255, 255), 2)\n",
    "show_img(\"watermarked image\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
